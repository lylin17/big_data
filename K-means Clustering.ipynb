{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read csv file containing subset data (csv file uploaded into databricks as Community5.csv)\n",
    "from pyspark.sql.types import *\n",
    "schema = StructType([StructField(\"Month\", IntegerType()),StructField(\"Weekday\", IntegerType()),StructField(\"Time_period\", IntegerType()),StructField(\"Fare\", IntegerType()), StructField(\"Pickup\", StringType()),StructField(\"Dropoff\",StringType())]) \n",
    "data = spark.read.csv(\"/FileStore/tables/Community5.csv\",header=True,schema=schema)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# restrict dataset to high fare trips\n",
    "data = data.where(\"Fare = 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let Month variable start from 0 to be consistent with other variables\n",
    "from pyspark.sql import SQLContext\n",
    "data.registerTempTable(\"data\")\n",
    "data = sqlContext.sql(\"SELECT Month-1 AS Month, Weekday, Time_period, Fare, Pickup, Dropoff FROM data\")\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create one-hot vector from categorical variables\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer \n",
    "from pyspark.ml.feature import OneHotEncoder \n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#Dropoff column to stringindex\n",
    "indexer = [StringIndexer(inputCol = column,outputCol=column+\"String\").fit(data) for column in data.columns[4:6]]\n",
    "pipeline = Pipeline(stages = indexer)                                                                                                   \n",
    "data2 = pipeline.fit(data).transform(data)\n",
    "data2 = data2.select(\"Month\",\"Weekday\",\"Time_period\",\"Fare\",\"PickupString\",\"DropoffString\")\n",
    "\n",
    "encoder = [OneHotEncoder(inputCol=column,outputCol = column+\"_ohe\",dropLast=False) for column in data2.columns]\n",
    "pipeline = Pipeline(stages = encoder)  \n",
    "data3 = pipeline.fit(data2).transform(data2)\n",
    "data3b = data3.select(\"Month_ohe\",\"Weekday_ohe\",\"Time_period_ohe\",\"Fare_ohe\",\"PickupString_ohe\", \"DropoffString_ohe\")\n",
    "\n",
    "va = VectorAssembler(inputCols=[\"Month_ohe\",\"Weekday_ohe\",\"Time_period_ohe\",\"Fare_ohe\",\"PickupString_ohe\",\"DropoffString_ohe\"], outputCol = \"features\")\n",
    "data4 = va.transform(data3b)\n",
    "data4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get sum of squares distance to centroid for different k to plot 'elbow' plot\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "for i in range(2, 51):\n",
    " kmeans = KMeans(k=i,maxIter = 100)\n",
    " clus = kmeans.fit(data4)\n",
    " kvalue = clus.computeCost(data4)\n",
    " print '' +str(i)+ \",\"+str(kvalue)+''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get cluster centers for optimal K\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "kmeans = KMeans(k=15,maxIter = 100)\n",
    "clus = kmeans.fit(data4)\n",
    "centers = clus.clusterCenters()\n",
    "\n",
    "#convert array to sql dataframe to be exported easily using 'display'\n",
    "centersdf = pd.DataFrame(centers)\n",
    "sqlCtx = SQLContext(sc)\n",
    "display(sqlCtx.createDataFrame(centersdf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "clustering",
  "notebookId": 2880132247777050
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
